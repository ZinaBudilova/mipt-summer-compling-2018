{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лемматизация\n",
    "\n",
    "Наши предложения на сегодня:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'ВКС 27 июля обнаружили и уничтожили запущенный с территории боевиков беспилотник, приближавшийся к авиабазе.'\n",
    "unkn_sent = 'Я пофиксил баг в продакшене.' # предложение с незнакомыми словами\n",
    "\n",
    "# омонимия\n",
    "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
    "homonym2 = 'Сорока своровала блестящее украшение со стола.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [mystem](https://tech.yandex.ru/mystem/)\n",
    "Как запускать:\n",
    "* можно скачать mystem и вызывать его [из командной строки с разными параметрами](https://tech.yandex.ru/mystem/doc/)\n",
    "* можно исполнять команды из пункта выше через питон (см. модуль `subprocess`)\n",
    "* [pymystem3](https://pythonhosted.org/pymystem3/pymystem3.html) - обертка для питона, работает медленнее, но это удобно.\n",
    "\n",
    "Сегодня мы будем работать с pymystem3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem_analyzer = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас мы запустили Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
    "* mystem_bin - путь к `mystem`, можно не указывать.\n",
    "* grammar_info - нужна ли грамматическая информация или только леммы (по дефолту нужна)\n",
    "* disambiguation - нужно ли снятие омонимии - дизамбигуация (по дефолту нужна)\n",
    "* entire_input - нужно ли сохранять в выводе все (пробелы всякие, например), или можно выкинуть (по дефолту оставляется все)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несколько моментов:\n",
    "* В Mystem нужно подавать строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст.\n",
    "* По возможности Mystem (и любые другие вещи этого рода) нужно инициализировать один раз, потому что инициализация занимает время и память.\n",
    "\n",
    "Можно просто лемматизировать текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ВКС', ' ', '27', ' ', 'июль', ' ', 'обнаруживать', ' ', 'и', ' ', 'уничтожать', ' ', 'запущенный', ' ', 'с', ' ', 'территория', ' ', 'боевик', ' ', 'беспилотник', ', ', 'приближаться', ' ', 'к', ' ', 'авиабаза', '.', '\\n']\n"
     ]
    }
   ],
   "source": [
    "print(mystem_analyzer.lemmatize(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А можно получить грамматическую информацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [], 'text': 'ВКС'},\n",
       " {'text': ' '},\n",
       " {'text': '27'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'июль', 'wt': 0.9979341289, 'gr': 'S,муж,неод=род,ед'},\n",
       "   {'lex': 'июль',\n",
       "    'wt': 0.002065871066,\n",
       "    'gr': 'S,имя,муж,од=(вин,ед|род,ед)'}],\n",
       "  'text': 'июля'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'обнаруживать',\n",
       "    'wt': 1,\n",
       "    'gr': 'V,пе=прош,мн,изъяв,сов'}],\n",
       "  'text': 'обнаружили'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'и', 'wt': 0.9999770357, 'gr': 'CONJ='},\n",
       "   {'lex': 'и', 'wt': 1.020511514e-05, 'gr': 'INTJ='},\n",
       "   {'lex': 'и',\n",
       "    'wt': 6.379604644e-06,\n",
       "    'gr': 'S,сокр=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'},\n",
       "   {'lex': 'и', 'wt': 6.37957056e-06, 'gr': 'PART='}],\n",
       "  'text': 'и'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'уничтожать', 'wt': 1, 'gr': 'V,пе=прош,мн,изъяв,сов'}],\n",
       "  'text': 'уничтожили'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'запущенный',\n",
       "    'wt': 0.991625177,\n",
       "    'gr': 'A=(вин,ед,полн,муж,неод|им,ед,полн,муж)'},\n",
       "   {'lex': 'запускать',\n",
       "    'wt': 0.00837482305,\n",
       "    'gr': 'V=(прош,вин,ед,прич,полн,муж,сов,страд,неод|прош,им,ед,прич,полн,муж,сов,страд)'}],\n",
       "  'text': 'запущенный'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'с', 'wt': 0.999977831, 'gr': 'PR='},\n",
       "   {'lex': 'с',\n",
       "    'wt': 2.216901809e-05,\n",
       "    'gr': 'S,сокр=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}],\n",
       "  'text': 'с'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'территория',\n",
       "    'wt': 1,\n",
       "    'gr': 'S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн)'}],\n",
       "  'text': 'территории'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'боевик',\n",
       "    'wt': 0.8623402597,\n",
       "    'gr': 'S,муж,од=(вин,мн|род,мн)'},\n",
       "   {'lex': 'боевик', 'wt': 0.1376597403, 'gr': 'S,муж,неод=род,мн'}],\n",
       "  'text': 'боевиков'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'беспилотник',\n",
       "    'wt': 0.503451027,\n",
       "    'qual': 'bastard',\n",
       "    'gr': 'S,муж,неод=(вин,ед|им,ед)'},\n",
       "   {'lex': 'беспилотник',\n",
       "    'wt': 0.496548973,\n",
       "    'qual': 'bastard',\n",
       "    'gr': 'S,муж,од=им,ед'}],\n",
       "  'text': 'беспилотник'},\n",
       " {'text': ', '},\n",
       " {'analysis': [{'lex': 'приближаться',\n",
       "    'wt': 1,\n",
       "    'gr': 'V,нп=(прош,вин,ед,прич,полн,муж,несов,действ,неод|прош,им,ед,прич,полн,муж,несов,действ)'}],\n",
       "  'text': 'приближавшийся'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'к', 'wt': 0.9999551798, 'gr': 'PR='},\n",
       "   {'lex': 'к',\n",
       "    'wt': 4.48202392e-05,\n",
       "    'gr': 'S,сокр=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}],\n",
       "  'text': 'к'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'авиабаза',\n",
       "    'wt': 1,\n",
       "    'gr': 'S,жен,неод=(пр,ед|дат,ед)'}],\n",
       "  'text': 'авиабазе'},\n",
       " {'text': '.'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer.analyze(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание.\n",
    "\n",
    "Попробуйте инициализировать Mystem с разными параметрами и посмотреть, что выходит с морфологическим анализом предложения. Конкретные вопросы:\n",
    "1. Что происходит с дизамбигуацией?\n",
    "2. Как хранится грамматическая информация?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [], 'text': 'ВКС'},\n",
       " {'text': ' '},\n",
       " {'text': '27'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'июль', 'wt': 0.9979341289, 'gr': 'S,муж,неод=род,ед'},\n",
       "   {'lex': 'июль',\n",
       "    'wt': 0.002065871066,\n",
       "    'gr': 'S,имя,муж,од=(вин,ед|род,ед)'}],\n",
       "  'text': 'июля'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'обнаруживать',\n",
       "    'wt': 1,\n",
       "    'gr': 'V,пе=прош,мн,изъяв,сов'}],\n",
       "  'text': 'обнаружили'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'и', 'wt': 0.9999770357, 'gr': 'CONJ='},\n",
       "   {'lex': 'и', 'wt': 1.020511514e-05, 'gr': 'INTJ='},\n",
       "   {'lex': 'и',\n",
       "    'wt': 6.379604644e-06,\n",
       "    'gr': 'S,сокр=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'},\n",
       "   {'lex': 'и', 'wt': 6.37957056e-06, 'gr': 'PART='}],\n",
       "  'text': 'и'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'уничтожать', 'wt': 1, 'gr': 'V,пе=прош,мн,изъяв,сов'}],\n",
       "  'text': 'уничтожили'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'запущенный',\n",
       "    'wt': 0.991625177,\n",
       "    'gr': 'A=(вин,ед,полн,муж,неод|им,ед,полн,муж)'},\n",
       "   {'lex': 'запускать',\n",
       "    'wt': 0.00837482305,\n",
       "    'gr': 'V=(прош,вин,ед,прич,полн,муж,сов,страд,неод|прош,им,ед,прич,полн,муж,сов,страд)'}],\n",
       "  'text': 'запущенный'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'с', 'wt': 0.999977831, 'gr': 'PR='},\n",
       "   {'lex': 'с',\n",
       "    'wt': 2.216901809e-05,\n",
       "    'gr': 'S,сокр=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}],\n",
       "  'text': 'с'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'территория',\n",
       "    'wt': 1,\n",
       "    'gr': 'S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн)'}],\n",
       "  'text': 'территории'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'боевик',\n",
       "    'wt': 0.8623402597,\n",
       "    'gr': 'S,муж,од=(вин,мн|род,мн)'},\n",
       "   {'lex': 'боевик', 'wt': 0.1376597403, 'gr': 'S,муж,неод=род,мн'}],\n",
       "  'text': 'боевиков'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'беспилотник',\n",
       "    'wt': 0.503451027,\n",
       "    'qual': 'bastard',\n",
       "    'gr': 'S,муж,неод=(вин,ед|им,ед)'},\n",
       "   {'lex': 'беспилотник',\n",
       "    'wt': 0.496548973,\n",
       "    'qual': 'bastard',\n",
       "    'gr': 'S,муж,од=им,ед'}],\n",
       "  'text': 'беспилотник'},\n",
       " {'text': ', '},\n",
       " {'analysis': [{'lex': 'приближаться',\n",
       "    'wt': 1,\n",
       "    'gr': 'V,нп=(прош,вин,ед,прич,полн,муж,несов,действ,неод|прош,им,ед,прич,полн,муж,несов,действ)'}],\n",
       "  'text': 'приближавшийся'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'к', 'wt': 0.9999551798, 'gr': 'PR='},\n",
       "   {'lex': 'к',\n",
       "    'wt': 4.48202392e-05,\n",
       "    'gr': 'S,сокр=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}],\n",
       "  'text': 'к'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'авиабаза',\n",
       "    'wt': 1,\n",
       "    'gr': 'S,жен,неод=(пр,ед|дат,ед)'}],\n",
       "  'text': 'авиабазе'},\n",
       " {'text': '.'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "mystem_analyzer = Mystem(disambiguation=False)\n",
    "mystem_analyzer.analyze(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'за', 'wt': 1, 'gr': 'PR='}], 'text': 'За'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'время', 'wt': 1, 'gr': 'S,сред,неод=(вин,ед|им,ед)'}],\n",
       "  'text': 'время'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'обучение',\n",
       "    'wt': 1,\n",
       "    'gr': 'S,сред,неод=(вин,мн|род,ед|им,мн)'}],\n",
       "  'text': 'обучения'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'я', 'wt': 0.9999716281, 'gr': 'SPRO,ед,1-л=им'}],\n",
       "  'text': 'я'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'прослушивать',\n",
       "    'wt': 1,\n",
       "    'gr': 'V,пе=прош,ед,изъяв,муж,сов'}],\n",
       "  'text': 'прослушал'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'много', 'wt': 0.0002164204767, 'gr': 'ADV=срав'}],\n",
       "  'text': 'больше'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'сорок',\n",
       "    'wt': 0.8710292664,\n",
       "    'gr': 'NUM=(пр|дат|род|твор)'}],\n",
       "  'text': 'сорока'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'курс', 'wt': 0.6284122441, 'gr': 'S,муж,неод=род,мн'}],\n",
       "  'text': 'курсов'},\n",
       " {'text': '.'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer = Mystem(disambiguation=True)\n",
    "mystem_analyzer.analyze(homonym1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'сорок',\n",
       "    'wt': 0.8710292664,\n",
       "    'gr': 'NUM=(пр|дат|род|твор)'},\n",
       "   {'lex': 'сорока', 'wt': 0.1210970041, 'gr': 'S,жен,од=им,ед'},\n",
       "   {'lex': 'сорока', 'wt': 0.00787372947, 'gr': 'S,жен,неод=им,ед'}],\n",
       "  'text': 'Сорока'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'своровать',\n",
       "    'wt': 1,\n",
       "    'gr': 'V,сов,пе=прош,ед,изъяв,жен'}],\n",
       "  'text': 'своровала'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'блестящий',\n",
       "    'wt': 0.6831493248,\n",
       "    'gr': 'A=(вин,ед,полн,сред|им,ед,полн,сред|срав)'},\n",
       "   {'lex': 'блестеть',\n",
       "    'wt': 0.3168506752,\n",
       "    'gr': 'V,несов,нп=(непрош,вин,ед,прич,полн,сред,действ|непрош,им,ед,прич,полн,сред,действ)'}],\n",
       "  'text': 'блестящее'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'украшение',\n",
       "    'wt': 1,\n",
       "    'gr': 'S,сред,неод=(вин,ед|им,ед)'}],\n",
       "  'text': 'украшение'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'со', 'wt': 1, 'gr': 'PR='}], 'text': 'со'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'стол', 'wt': 1, 'gr': 'S,муж,неод=род,ед'}],\n",
       "  'text': 'стола'},\n",
       " {'text': '.'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer = Mystem(disambiguation=False)\n",
    "mystem_analyzer.analyze(homonym2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'сорока', 'wt': 0.1210970041, 'gr': 'S,жен,од=им,ед'}],\n",
       "  'text': 'Сорока'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'своровать',\n",
       "    'wt': 1,\n",
       "    'gr': 'V,сов,пе=прош,ед,изъяв,жен'}],\n",
       "  'text': 'своровала'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'блестящий',\n",
       "    'wt': 0.6831493248,\n",
       "    'gr': 'A=(вин,ед,полн,сред|им,ед,полн,сред|срав)'}],\n",
       "  'text': 'блестящее'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'украшение',\n",
       "    'wt': 1,\n",
       "    'gr': 'S,сред,неод=(вин,ед|им,ед)'}],\n",
       "  'text': 'украшение'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'со', 'wt': 1, 'gr': 'PR='}], 'text': 'со'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'стол', 'wt': 1, 'gr': 'S,муж,неод=род,ед'}],\n",
       "  'text': 'стола'},\n",
       " {'text': '.'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mystem_analyzer = Mystem(disambiguation=True)\n",
    "mystem_analyzer.analyze(homonym2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Другие фичи\n",
    "Незнакомые слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'я', 'wt': 0.9999716281, 'gr': 'SPRO,ед,1-л=им'}],\n",
       "  'text': 'Я'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'пофиксить',\n",
       "    'wt': 0.6996286204,\n",
       "    'qual': 'bastard',\n",
       "    'gr': 'V,несов,пе=прош,ед,изъяв,муж'}],\n",
       "  'text': 'пофиксил'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'баг',\n",
       "    'wt': 1,\n",
       "    'qual': 'bastard',\n",
       "    'gr': 'S,гео,муж,неод=(вин,ед|им,ед)'}],\n",
       "  'text': 'баг'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'в', 'wt': 0.9999917878, 'gr': 'PR='}], 'text': 'в'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'продакшень',\n",
       "    'wt': 0.2241225571,\n",
       "    'qual': 'bastard',\n",
       "    'gr': 'S,муж,неод=пр,ед'}],\n",
       "  'text': 'продакшене'},\n",
       " {'text': '.'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer = Mystem(disambiguation=True)\n",
    "mystem_analyzer.analyze(unkn_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [pymorphy2](http://pymorphy2.readthedocs.io/en/latest/)\n",
    "Это модуль на питоне (то есть всё организовано через ООП), довольно быстрый и с кучей функций.\n",
    "\n",
    "Как запускать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "pymorphy2_analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, тк не понимает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ВКС',\n",
       " '27',\n",
       " 'июля',\n",
       " 'обнаружили',\n",
       " 'и',\n",
       " 'уничтожили',\n",
       " 'запущенный',\n",
       " 'с',\n",
       " 'территории',\n",
       " 'боевиков',\n",
       " 'беспилотник',\n",
       " ',',\n",
       " 'приближавшийся',\n",
       " 'к',\n",
       " 'авиабазе',\n",
       " '.']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(sent)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='территории', tag=OpencorporaTag('NOUN,inan,femn sing,loct'), normal_form='территория', score=0.714285, methods_stack=((<DictionaryAnalyzer>, 'территории', 40, 6),)),\n",
       " Parse(word='территории', tag=OpencorporaTag('NOUN,inan,femn sing,gent'), normal_form='территория', score=0.095238, methods_stack=((<DictionaryAnalyzer>, 'территории', 40, 1),)),\n",
       " Parse(word='территории', tag=OpencorporaTag('NOUN,inan,femn sing,datv'), normal_form='территория', score=0.095238, methods_stack=((<DictionaryAnalyzer>, 'территории', 40, 2),)),\n",
       " Parse(word='территории', tag=OpencorporaTag('NOUN,inan,femn plur,nomn'), normal_form='территория', score=0.047619, methods_stack=((<DictionaryAnalyzer>, 'территории', 40, 7),)),\n",
       " Parse(word='территории', tag=OpencorporaTag('NOUN,inan,femn plur,accs'), normal_form='территория', score=0.047619, methods_stack=((<DictionaryAnalyzer>, 'территории', 40, 10),))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terra = pymorphy2_analyzer.parse(tokens[8])\n",
    "terra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "территория\n",
      "NOUN,inan,femn sing,loct\n",
      "NOUN\n"
     ]
    }
   ],
   "source": [
    "print(terra[0].normal_form) # лемма\n",
    "print(terra[0].tag) # тэг\n",
    "print(terra[0].tag.POS) # часть речи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание.\n",
    "Напишите лемматизацию предложения `sent` через pymorphy2. На выходе должен быть массив лемм.\n",
    "Сравните лемматизацию с предложенной mystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вкс\n",
      "27\n",
      "июль\n",
      "обнаружить\n",
      "и\n",
      "уничтожить\n",
      "запустить\n",
      "с\n",
      "территория\n",
      "боевик\n",
      "беспилотник\n",
      ",\n",
      "приближаться\n",
      "к\n",
      "авиабаза\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "for i in range(len(tokens)):\n",
    "    word = pymorphy2_analyzer.parse(tokens[i])\n",
    "    print(word[0].normal_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Другие фичи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Незнакомые слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('я',\n",
       "  OpencorporaTag('NPRO,1per sing,nomn'),\n",
       "  ((<DictionaryAnalyzer>, 'я', 3100, 0),)),\n",
       " ('пофиксила',\n",
       "  OpencorporaTag('NOUN,inan,femn plur,gent'),\n",
       "  ((<DictionaryAnalyzer>, 'сил', 55, 8), (<UnknownPrefixAnalyzer>, 'пофик'))),\n",
       " ('баг',\n",
       "  OpencorporaTag('NOUN,inan,masc sing,accs'),\n",
       "  ((<DictionaryAnalyzer>, 'баг', 19, 3),)),\n",
       " ('в', OpencorporaTag('PREP'), ((<DictionaryAnalyzer>, 'в', 375, 0),)),\n",
       " ('продакшен',\n",
       "  OpencorporaTag('NOUN,inan,masc,Geox sing,loct'),\n",
       "  ((<FakeDictionary>, 'продакшене', 32, 5), (<KnownSuffixAnalyzer>, 'шене'))),\n",
       " ('.', OpencorporaTag('PNCT'), ((<PunctuationAnalyzer>, '.'),))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmata = []\n",
    "for token in word_tokenize(unkn_sent):\n",
    "    ana = pymorphy2_analyzer.parse(token)[0]\n",
    "    lemmata.append((ana.normal_form, ana.tag, ana.methods_stack))\n",
    "lemmata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Склонение слов и согласование слов с числительными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inflection: территорию\n",
      "locative + 1: территории\n",
      "locative + 3: территориях\n",
      "locative + 5: территориях\n",
      "nominative + 1: территория\n",
      "nominative + 3: территории\n",
      "nominative + 5: территорий\n"
     ]
    }
   ],
   "source": [
    "loc_terra = terra[0]\n",
    "print('inflection:', loc_terra.inflect({'accs'}).word)\n",
    "print('locative + 1:', loc_terra.make_agree_with_number(1).word)\n",
    "print('locative + 3:', loc_terra.make_agree_with_number(3).word)\n",
    "print('locative + 5:', loc_terra.make_agree_with_number(5).word)\n",
    "\n",
    "nom_terra = loc_terra.inflect({'nomn'})\n",
    "print('nominative + 1:',nom_terra.make_agree_with_number(1).word)\n",
    "print('nominative + 3:',nom_terra.make_agree_with_number(3).word)\n",
    "print('nominative + 5:',nom_terra.make_agree_with_number(5).word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Снятие омонимии\n",
    "mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'сорока', 'analysis': [{'gr': 'NUM=(пр|дат|род|твор)', 'lex': 'сорок'}]}\n",
      "{'text': 'Сорока', 'analysis': [{'gr': 'S,жен,од=им,ед', 'lex': 'сорока'}]}\n"
     ]
    }
   ],
   "source": [
    "mystem_analyzer = Mystem() # инициализирую объект снова, потому что было задание на разные параметры, я хочу дефолтные\n",
    "\n",
    "print(mystem_analyzer.analyze(homonym1)[-5])\n",
    "print(mystem_analyzer.analyze(homonym2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Parse(word='сорока', tag=OpencorporaTag('NUMR loct'), normal_form='сорок', score=0.285714, methods_stack=((<DictionaryAnalyzer>, 'сорока', 2802, 5),))\n"
     ]
    }
   ],
   "source": [
    "ana1 = pymorphy2_analyzer.parse(homonym1.split(' ')[-2])\n",
    "ana2 = pymorphy2_analyzer.parse(homonym2.split(' ')[0])\n",
    "print(ana1 == ana2)\n",
    "print(ana1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Стоп-слова\n",
    "Списки стоп-слов для русского есть разные, можно погуглить, а можно взять из nltk. Может быть, вы посчитаете нужным что-то в него добавить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Знаки препинания\n",
    "Списки знаков препинания тоже уже есть в питоне. Но этот список тоже может понадобиться пополнить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~^'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation + '^'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "\n",
    "## Задание 1.\n",
    "Напишите функцию, предобрабатывающую текст. Она вам пригодится для проекта. В предобработку входит:\n",
    "* токенизация\n",
    "* лемматизация (при которой произойдет lowercase)\n",
    "* удаление знаков препинания и стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "pymorphy2_analyzer = MorphAnalyzer()\n",
    "\n",
    "\n",
    "def preprocessing(text):\n",
    "    \"\"\"\n",
    "    Processes input text for further use in search engine.\n",
    "    :param text: str: input text.\n",
    "    :return: list[str]: lemmata list\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    prepr = []\n",
    "    tokens = word_tokenize(text)\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] not in stopwords.words('russian') and tokens[i] not in punctuation:\n",
    "            word = pymorphy2_analyzer.parse(tokens[i])\n",
    "            prepr.append(word[0].normal_form)\n",
    "    return prepr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['вкс',\n",
       " '27',\n",
       " 'июль',\n",
       " 'обнаружить',\n",
       " 'уничтожить',\n",
       " 'запустить',\n",
       " 'территория',\n",
       " 'боевик',\n",
       " 'беспилотник',\n",
       " 'приближаться',\n",
       " 'авиабаза']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text='ВКС 27 июля обнаружили и уничтожили запущенный с территории боевиков беспилотник, приближавшийся к авиабазе.'\n",
    "preprocessing(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.\n",
    "\n",
    "Это часть вашего проекта.\n",
    "\n",
    "Прочитайте корпус, предобработайте каждый документ и сделайте (и сохраните в формате json) обратный индекс. Обратный индекс - словарь, где для каждого слова из корпуса есть список документов, в которых оно есть. Также подумайте, какую информацию по корпусу вам нужно сохранить (вспомните, что нужно для подсчета Okapi BM25) и сохраните ее тоже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Computes Okapi BM25 for a particular document and one word in a query.\n",
    "    NB: min IDF 0 (use built-in max function)\n",
    "    :param n: number of docs with a word                 \n",
    "    :param qf: raw word frequence in doc                \n",
    "    :param N: number of docs in a collection\n",
    "    :param dl: doc length (in words)                    \n",
    "    :param avdl: average doc length in a collection     \n",
    "    :return: float: BM25 score\n",
    "    \"\"\"\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "pymorphy2_analyzer = MorphAnalyzer()\n",
    "import json\n",
    "import os\n",
    "\n",
    "def preprocessing(text):\n",
    "    prepr = []\n",
    "    tokens = word_tokenize(text)\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] not in stopwords.words('russian') and tokens[i] not in punctuation:\n",
    "            word = pymorphy2_analyzer.parse(tokens[i])\n",
    "            prepr.append(word[0].normal_form)\n",
    "    return prepr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_index(docs):\n",
    "    d={}\n",
    "    for i in docs:\n",
    "        value = docs[i]\n",
    "        for j in value:\n",
    "            if j in d:\n",
    "                if i in d[j]:\n",
    "                    d[j][i] += 1\n",
    "                else:\n",
    "                    d[j][i] = 1\n",
    "            else:\n",
    "                d[j]={i:1}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = {}\n",
    "ind = {}\n",
    "for path in os.listdir('rus_corpus'):\n",
    "    if os.path.isfile('./rus_corpus/' + path):\n",
    "        with open('./rus_corpus/' + path, encoding='utf-8-sig') as f:\n",
    "            text = preprocessing(f.read())\n",
    "            lens[path] = len(text)\n",
    "            ind[path] = text\n",
    "inv_ind = {}            \n",
    "inv_ind = inverted_index(ind)\n",
    "\n",
    "json.dump(inv_ind, open('inv_index.txt','w', encoding='utf-8-sig'), ensure_ascii=False, indent=2)\n",
    "json.dump(lens, open('lens.txt','w', encoding='utf-8-sig'), ensure_ascii=False, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
